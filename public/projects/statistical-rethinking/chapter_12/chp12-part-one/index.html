<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    
    
        
            
            <meta name="twitter:card" content="summary_large_image"/>
            <meta name="twitter:image" content="/images/tea_with_books.jpg"/>
        
    



<meta name="twitter:title" content="Of Monsters and Mixtures"/>
<meta name="twitter:description" content=""/>
<meta name="twitter:site" content="@corrieaar"/>



  	<meta property="og:title" content="Of Monsters and Mixtures &middot; Samples of Thoughts" />
  	<meta property="og:site_name" content="Samples of Thoughts" />
  	<meta property="og:url" content="/projects/statistical-rethinking/chapter_12/chp12-part-one/" />

    
        
            <meta property="og:image" content="/images/tea_with_books.jpg"/>
        
    
    
    <meta property="og:description" content="" />
  	<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2019-04-14T00:00:00Z" />

    
    <meta property="article:tag" content="Statistical Rethinking" />
    
    <meta property="article:tag" content="Bayesian" />
    
    

    <title>Of Monsters and Mixtures &middot; Samples of Thoughts</title>

    
    <meta name="description" content="Over-dispersed outcomes For the beta-binomial model, we’ll make use of the beta distribution. The beta distribution is a probability distribution over probabili" />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/images/favicon.ico">
	  <link rel="apple-touch-icon" href="/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="/css/nav.css" />

    
    
    


<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/googlecode.min.css' rel='stylesheet' type='text/css' />



  
     
      
          <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Samples of Thoughts" />
      
      
    
    <meta name="generator" content="Hugo 0.55.5" />

    <link rel="canonical" href="/projects/statistical-rethinking/chapter_12/chp12-part-one/" />

    
      
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name":  null 
    },
    "author": {
        "@type": "Person",
        "name":  null ,
        
        "url":  null ,
        "sameAs": [
            
            
             
             
             
             
             
            
        ]
    },
    "headline": "Of Monsters and Mixtures",
    "name": "Of Monsters and Mixtures",
    "wordCount":  1659 ,
    "timeRequired": "PT8M",
    "inLanguage": {
      "@type": "Language",
      "alternateName": "en"
    },
    "url": "/projects/statistical-rethinking/chapter_12/chp12-part-one/",
    "datePublished": "2019-04-14T00:00Z",
    "dateModified": "2019-04-14T00:00Z",
    
    "image": {
        "@type": "ImageObject",
        "url": "/images/tea_with_books.jpg",
        "width": 3000,
        "height": 1445
    },
    
    "keywords": "Statistical Rethinking, Bayesian",
    "description": "",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/projects/statistical-rethinking/chapter_12/chp12-part-one/"
    }
}
    </script>
    


    

    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
    
    




<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#40485A",
          "text": "#ffffff"
        },
        "button": {
          "background": "#5B5A68",
          "text": "#ffffff"
        }
      },
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on my website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://cookies.insites.com"
      }
    })});
</script>


</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/projects">Projects</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/talks">Talks</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/about">About</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/">Home</a>
            </li>
        
        
    </ul>

    
    <a class="subscribe-button icon-feed" href="/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">



  
 <header class="main-header post-head" style="background-image: url(/images/tea_with_books.jpg)"> 
  
  <nav class="main-nav overlay clearfix">



      <ul>
        
			<li> <a class="blog-logo" href="/">Home</a> </li>
			  
			<li> <a class="blog-logo" href="/about">About</a> </li>
			  
			<li> <a class="blog-logo" href="/talks">Talks</a> </li>
			  
			<li> <a class="blog-logo" href="/projects">Projects</a> </li>
			  

            
              <a class="menu-button icon-feed" href="">&nbsp;&nbsp;Subscribe</a>
            
            
      
       </ul>
    </nav>
    
     <div class="vertical">
        <div class="main-header-content inner">
            


    <a class="bloglogo" href="https://github.com/corriebar" target="_blank">
    <span class="icon-github" style="color:white;font-size:2em"></span>
    </a>
&nbsp;









    <a class="bloglogo" href="https://twitter.com/corrieaar" target="_blank">
        <span class="icon-twitter" style="color:white;font-size:2em"></span>
    </a>
&nbsp;














            <h1 class="page-title">Samples of Thoughts</h1>
            <h2 class="page-description">about data, statistics  and everything in between</h2>
        </div>
    </div>  
    


</header>



<main class="content" role="main">




  <article class="post projects">

    <header class="post-header">
        <h1 class="post-title">Of Monsters and Mixtures</h1>
        <small></small>

        <section class="post-meta">
        
            <p class="post-reading post-line">
            <span>Estimated reading time: 8 min</span>
            </p>
        
        
        
         
          <span class="post-tag small"><a href="/tags/statistical-rethinking/">#Statistical Rethinking</a></span>
         
          <span class="post-tag small"><a href="/tags/bayesian/">#Bayesian</a></span>
         
        </section>
    </header>

    <section class="post-content">
      


<div id="over-dispersed-outcomes" class="section level2">
<h2>Over-dispersed outcomes</h2>
<p>For the beta-binomial model, we’ll make use of the beta distribution. The beta distribution is a probability distribution over probabilities (over the interval <span class="math inline">\([0, 1]\)</span>).</p>
<pre class="r"><code>library(rethinking)
pbar &lt;- 0.5
theta &lt;- 5
curve( dbeta2( x, pbar, theta), from=0, to=1, xlab=&quot;probability&quot;, ylab=&quot;Density&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>There are different ways to parametrize the beta distribution:</p>
<pre class="r"><code>dbeta2 &lt;- function( x , prob , theta , log=FALSE ) {
    a &lt;- prob * theta
    b &lt;- (1-prob) * theta
    dbeta( x , shape1=a , shape2=b , log=log )
}</code></pre>
<p>We use the beta-binomial for the <code>UCBadmit</code> data, which is over-dispersed if we ignore department (since the admission rate varied quite a lot for different departments).
Our model looks as follows:
<span class="math display">\[\begin{align*}
A_i &amp;\sim \text{BetaBinomial}(N_i, \bar{p}_i, \theta) \\
\text{logit}(\bar{p}_i) &amp;= \alpha_{\text{GID}[i]}) \\
\alpha_j &amp;\sim \text{Normal}(0, 1.5) \\
\theta &amp;\sim \text{Exponential}(1)
\end{align*}\]</span>
where <span class="math inline">\(A\)</span> is <code>admit</code>, <span class="math inline">\(N\)</span> is the number of applications <code>applications</code>, and GID<span class="math inline">\([i]\)</span> is gender id, 1 for male and 2 for female.</p>
<pre class="r"><code>data(&quot;UCBadmit&quot;)
d &lt;- UCBadmit
d$gid &lt;- ifelse(d$applicant.gender == &quot;male&quot;, 1L, 2L)
dat &lt;- list(A = d$admit, N = d$applications, gid=d$gid)

m12.1 &lt;- ulam(
  alist(
    A ~ dbetabinom( N, pbar, theta),
    logit(pbar) &lt;- a[gid],
    a[gid] ~ dnorm(0, 1.5),
    theta ~ dexp(1)
  ), data=dat, chains=4
)</code></pre>
<pre class="r"><code>post &lt;- extract.samples(m12.1 )
post$da &lt;- post$a[,1] - post$a[,2]
precis( post, depth=2)</code></pre>
<pre><code>            mean        sd       5.5%     94.5%  histogram
a[1]  -0.4170432 0.4327273 -1.1055429 0.2583752    ▁▂▇▇▂▁▁
a[2]  -0.3063994 0.4285321 -0.9805098 0.4067581    ▁▁▅▇▃▁▁
theta  2.6763961 0.9493179  1.3789576 4.2942542  ▁▃▇▃▁▁▁▁▁
da    -0.1106438 0.5862838 -1.0271344 0.8384815 ▁▁▁▃▇▇▂▁▁▁</code></pre>
<p><code>a[1]</code> is the log-odds of admission for male applicants which is lower than <code>a[2]</code>, the log-odds for female applicants. This might suggest there is a diffenrece in admission rates by gender, but the posterior difference <code>da</code> is highly uncertain with probability mass both above and below zero.</p>
<p>We can visualize the posterior Beta-distribution:</p>
<pre class="r"><code>gid &lt;- 2
# draw posterior mean beta distribution
curve( dbeta2(x, mean( logistic(post$a[, gid])), mean(post$theta)), from=0, to=1,
       ylab=&quot;Density&quot;, xlab=&quot;probability admit&quot;, ylim=c(0,3), lwd=2)

# draw 50 beta distributions sampled from posterior
for ( i in 1:50 ) {
  p &lt;- logistic( post$a[i, gid ] )
  theta &lt;- post$theta[i]
  curve( dbeta2(x, p, theta), add=T,col=col.alpha(&quot;black&quot;, 0.2))
}
mtext(&quot;distribution of female admission rates&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>There is a tendency for admission rates below 40% but the most plausible (the mean Beta-distribution) also allows for very high admission rates above 80%. This way, the model incorporated the high variation among departments.</p>
<pre class="r"><code>postcheck(m12.1)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The prediction intervals are very wide, the model incorporated such a wide variance since even though it doesn’t see the different departments, it does see heterogeneity across rows.</p>
</div>
<div id="negative-binomial" class="section level2">
<h2>Negative-Binomial</h2>
<p>Similar as with the Beta-Binomial, we can fit a Poisson model, where each observation has its own rate. The rate comes from a common gamma distribution.</p>
<pre class="r"><code>phi &lt;- 2
lambda &lt;- 1
curve( dgamma( x, shape=phi, rate=lambda), from=0, to=20, xlab=&quot;rate&quot;, ylab=&quot;probability density&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We check again the Kline data of the tool counts for different islands, this time using the negative-binomial model.</p>
<pre class="r"><code>data(Kline)
d &lt;- Kline
d$P &lt;- standardize( log( d$population ) )
d$contact_id &lt;- ifelse( d$contact == &quot;high&quot;, 2L, 1L)

dat2 &lt;- list(
  TT = d$total_tools,
  P = d$population,
  cid = d$contact_id
)

m12.3 &lt;- ulam(
  alist(
    TT ~ dgampois( lambda, phi ),
    lambda &lt;- exp( a[cid])*P^b[cid] / g,
    a[cid] ~ dnorm(1, 1),
    b[cid] ~ dexp(1),
    g ~ dexp(1),
    phi ~ dexp(1)
  ), data=dat2, chains=4, log_lik = TRUE
)</code></pre>
<p>For comparison, we also fit our model from before, using a pure Poisson model.</p>
<pre class="r"><code>m11.11 &lt;- ulam(
  alist(
    TT ~ dpois(lambda),
    lambda &lt;- exp( a[cid] )*P^b[cid] / g,
    a[cid] ~ dnorm(1,1),
    b[cid] ~ dexp(1),
    g ~ dexp(1)
  ), data=dat2, chains=4, log_lik = T
)</code></pre>
<pre class="r"><code>k &lt;- PSIS( m11.11 , pointwise=TRUE )$k
par(bty=&quot;l&quot;, mfrow=c(1,2))
plot( d$population, d$total_tools, xlab=&quot;population&quot;, ylab=&quot;total tools&quot;,
      col=rangi2, pch=ifelse(dat2$cid == 1, 1, 16), lwd=2,
      ylim=c(0,74), cex=1+normalize(k) )

ns &lt;- 100
P_seq &lt;- seq(from=0, to=12.55, length.out = ns)
pop_seq &lt;- exp( P_seq )

lambda &lt;- link(m12.3, data=data.frame(P = pop_seq, cid=1))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=2, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)

lambda &lt;- link(m12.3, data=data.frame(P = pop_seq, cid=2))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=1, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)
text(c(9e4, 1e5), c(68, 50), labels=c(&quot;high contact&quot;, &quot;low contact&quot;))
mtext(&quot;gamma-Poisson model&quot;)


plot( d$population, d$total_tools, xlab=&quot;population&quot;, ylab=&quot;total tools&quot;,
      col=rangi2, pch=ifelse(dat2$cid == 1, 1, 16), lwd=2,
      ylim=c(0,74), cex=1+normalize(k) )

lambda &lt;- link(m11.11, data=data.frame(P = pop_seq, cid=1))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=2, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)

lambda &lt;- link(m11.11, data=data.frame(P = pop_seq, cid=2))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=1, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)
mtext(&quot;pure Poisson model&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-10-1.png" width="1056" /></p>
<p>Again, we can see that the mixture model incorporates much more uncertainty compared to the pure, non-mixed model.</p>
</div>
<div id="zero-inflated-outcomes" class="section level2">
<h2>Zero-inflated outcomes</h2>
<p>Often, the things we measure are not from any pure process but rather mixtures of different processes. One such example is count data. Very often a count of zero can happen in more than one way: either the rate of processes is low or the process that generates events failed to start in the first place.</p>
<p>If we go back to our example of monks writing manuscripts. Many monks work on manuscripts and on some days, they’ll finish a few. The rate is thus very low and there will be days where no manuscript is finished. However, imagine that on some days, the monks take a break and instead of writing, they open the wine cellar. On these days, no manuscript will be produced. So we have two ways how we end up with a count of no manuscripts.</p>
<p>Let’s simulate this process.
We assume that the probability on any day that the monks are drinking instead of working is 20%. The rate at which they produce manuscripts is one manuscript per day.</p>
<pre class="r"><code>prob_drink &lt;- 0.2
rate_work &lt;- 1</code></pre>
<p>We simulate counts for one whole year. First, for each day we simulate using a binomial process, if the monks were drinking or working.</p>
<pre class="r"><code>N &lt;- 365
set.seed(365)
drink &lt;- rbinom( N, 1, prob_drink)</code></pre>
<p>Next, for each day we simulate how many manuscripts the monks would have finished and multiply with 0 if on a day the monks were drinking.</p>
<pre class="r"><code>y &lt;- (1-drink)*rpois(N, rate_work)</code></pre>
<p>Let’s visualize the simulated data:</p>
<pre class="r"><code>simplehist( y, xlab=&quot;manuscripts completed&quot;, lwd=4)
zeros_drink &lt;- sum(drink)
zeros_work &lt;- sum(y==0 &amp; drink == 0)
zeros_total &lt;- sum(y==0)
lines(c(0,0), c(zeros_work, zeros_total), lwd=4, col=rangi2 )</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>The blue part signifies the days were no manuscripts were completed because the monks were drinking. The total number of zeros is inflated, relative to a typical Poisson distribution.</p>
<p>To fit this Zero-Inflated Poisson model, we can use the function <code>dzipois()</code> provided in the Rethinking-package.
The prior for the probability of drinking is nudged so that there is more mass below 0.5, the monks probably don’t drink more often than not:</p>
<pre class="r"><code>ap &lt;- rnorm(1000, -1.5, 1)
p &lt;- inv_logit(ap)
dens(p)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>The model then looks as follows:</p>
<pre class="r"><code>m12.4 &lt;- ulam(
  alist(
    y ~ dzipois( p, lambda ),
    # p = probability monks are drinking
    logit(p) &lt;- ap,
    # lambda = rate for completing manuscripts
    log(lambda) &lt;- al,
    ap ~ dnorm( -1.5, 1 ),
    al ~ dnorm( 1, 0.5 )
  ), data=list(y=as.integer(y)), chains=4)</code></pre>
<pre class="r"><code>precis(m12.4)</code></pre>
<pre><code>          mean         sd       5.5%      94.5%    n_eff    Rhat4
ap -1.27943087 0.37228853 -1.9347033 -0.7735818 584.0565 1.003241
al  0.01190568 0.09243819 -0.1376475  0.1624185 649.3856 1.009246</code></pre>
<p>On the natural scale, those estimates are:</p>
<pre class="r"><code>inv_logit(-1.28)</code></pre>
<pre><code>[1] 0.2175502</code></pre>
<pre class="r"><code>exp(0.01)</code></pre>
<pre><code>[1] 1.01005</code></pre>
<p>Note that we get a very good estimate of the proportion of days the monks drink, even though we can’t say for any particular day whether or not they drank.</p>
<p>The function <code>dzipois()</code> already does most of the work for us, but let’s check how such a model is implemented:</p>
<pre class="r"><code>m12.4_alt &lt;- ulam(
  alist(
    # log-lkhd for non-zero values: (1-p)=prob of not drinking
    # poisson_lpmf = probability of finishing y manuscripts
    y|y&gt;0 ~ custom( log( 1-p ) + poisson_lpmf(y|lambda ) ),
    # log-lkhd for zero values: p=prob of drinking
    # (1-p)*exp(lambda) = prob of finishing zero manuscripts when not drinking
    y|y==0 ~ custom( log( p + (1-p)*exp(lambda ) )),
    logit(p) &lt;- ap,
    log(lambda) &lt;- al,
    ap ~ dnorm(-1.5, 1),
    al ~ dnorm(1, 0.5)
  ), data=list(y=as.integer(y)), chains=4
)</code></pre>
<p>However, for numerical stability, it is better to use the functions <code>log1m(p)</code> for <code>log(1-p)</code> and <code>log_mix(p, 0, poisson_lpmf(0|lambda))</code> instead of <code>log(p + (1-p)*exp(lambda))</code>.</p>
<pre class="r"><code>m12.4_alt &lt;- ulam(
  alist(
    # log-lkhd for non-zero values: (1-p)=prob of not drinking
    # poisson_lpmf = probability of finishing y manuscripts
    y|y&gt;0 ~ custom( log1m( p ) + poisson_lpmf(y|lambda ) ),
    # log-lkhd for zero values: p=prob of drinking
    # (1-p)*exp(lambda) = prob of finishing zero manuscripts when not drinking
    y|y==0 ~ custom( log_mix( p, 0, poisson_lpmf(0|lambda) ) ),
    logit(p) &lt;- ap,
    log(lambda) &lt;- al,
    ap ~ dnorm(-1.5, 1),
    al ~ dnorm(1, 0.5)
  ), data=list(y=as.integer(y)), chains=4
)</code></pre>
<p>This gives us the same estimates as <code>m12.4</code>:</p>
<pre class="r"><code>precis(m12.4_alt)</code></pre>
<pre><code>          mean         sd       5.5%      94.5%    n_eff     Rhat4
ap -1.26899142 0.34561667 -1.8757107 -0.8064936 605.9883 1.0004240
al  0.01130696 0.08613438 -0.1257928  0.1483133 601.1485 0.9994628</code></pre>
<p>It’s also helps to look at the stan code of the model:</p>
<pre class="r"><code>stancode(m12.4_alt)</code></pre>
<pre><code>data{
    int y[365];
}
parameters{
    real ap;
    real al;
}
model{
    real p;
    real lambda;
    al ~ normal( 1 , 0.5 );
    ap ~ normal( -1.5 , 1 );
    lambda = al;
    lambda = exp(lambda);
    p = ap;
    p = inv_logit(p);
    for ( i in 1:365 ) 
        if ( y[i] == 0 ) target += log_mix(p, 0, poisson_lpmf(0 | lambda));
    for ( i in 1:365 ) 
        if ( y[i] &gt; 0 ) target += log1m(p) + poisson_lpmf(y[i] | lambda);
}</code></pre>
<p>The most important of the model is in the <code>for</code> loop, iterating over each observation. It adds the log-likelihood to the variable <code>target</code> which is the log posterior mass. The suffix <code>_lpmf</code> means it’s the log probability mass function. (For continuous variables the suffix would be <code>_lpdf</code>, log probability density function).</p>
</div>

    
    </section>

  <footer class="post-footer">


    









<section class="author">
  <h4><a href="/">Corrie</a></h4>
  
  <p>Read <a href="/">more posts</a> by this author.</p>
  
  <div class="author-meta">
    
    
  </div>
</section>




    
<section class="share">
  <h4>Share this projects</h4>
  <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=Of%20Monsters%20and%20Mixtures&nbsp;-&nbsp;Samples%20of%20Thoughts&amp;url=%2fprojects%2fstatistical-rethinking%2fchapter_12%2fchp12-part-one%2f"
      onclick="window.open(this.href, 'twitter-share', 'width=550,height=421');return false;">
      <span class="hidden">Twitter</span>
  </a>
  <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=%2fprojects%2fstatistical-rethinking%2fchapter_12%2fchp12-part-one%2f"
      onclick="window.open(this.href, 'facebook-share','width=580,height=551');return false;">
      <span class="hidden">Facebook</span>
  </a>
  <a class="icon-linkedin" style="font-size: 1.4em" href="https://www.linkedin.com/shareArticle?mini=true&title=Of%20Monsters%20and%20Mixtures&url=%2fprojects%2fstatistical-rethinking%2fchapter_12%2fchp12-part-one%2f"
               onclick="window.open(this.href, 'linkedin-share', 'width=554,height=571');return false;">
    <span class="hidden">LinkedIn</span>
    </a>

</section>




    

<div id="disqus_thread"></div>
<script>




var disqus_config = function () {
this.page.url = "\/projects\/statistical-rethinking\/chapter_12\/chp12-part-one\/";  
this.page.identifier = "\/projects\/statistical-rethinking\/chapter_12\/chp12-part-one\/"; 
};

(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://corriebar-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>








  </footer>
</article>

</main>



    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Samples of Thoughts</a> 
        &copy; Corrie Bartelheimer 2020 &middot; </section>
        
    </footer>
    </div>
    <script type="text/javascript" src="/js/jquery.js"></script>
    <script type="text/javascript" src="/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/js/index.js"></script>
    
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>


    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML">
</script>


    
    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
</body>
</html>

