<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    
        <meta name="twitter:card" content="summary"/>
    



<meta name="twitter:title" content=""/>
<meta name="twitter:description" content=""/>
<meta name="twitter:site" content="@corrieaar"/>



  	<meta property="og:title" content=" &middot; Samples of Thoughts" />
  	<meta property="og:site_name" content="Samples of Thoughts" />
  	<meta property="og:url" content="/projects/statistical-rethinking/chapter_5/chapter5_ex/" />

    
        
            <meta property="og:image" content="/images/tea_with_books.jpg"/>
        
    
    
    <meta property="og:description" content="" />
  	<meta property="og:type" content="article" />
    <meta property="article:published_time" content="0001-01-01T00:00:00Z" />

    
    

    <title> &middot; Samples of Thoughts</title>

    
    <meta name="description" content="Chapter 5 - Exercises Corrie June 3, 2018
Chapter 5 - Exercises These are my solutions to the exercises from chapter 5.
Easy. 5E1. The following linear models a" />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/images/favicon.ico">
	  <link rel="apple-touch-icon" href="/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="/css/nav.css" />

    
    
    


<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/googlecode.min.css' rel='stylesheet' type='text/css' />



  
     
      
          <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Samples of Thoughts" />
      
      
    
    <meta name="generator" content="Hugo 0.55.5" />

    <link rel="canonical" href="/projects/statistical-rethinking/chapter_5/chapter5_ex/" />

    
      
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name":  null 
    },
    "author": {
        "@type": "Person",
        "name":  null ,
        
        "url":  null ,
        "sameAs": [
            
            
             
             
             
             
             
            
        ]
    },
    "headline": "",
    "name": "",
    "wordCount":  2978 ,
    "timeRequired": "PT14M",
    "inLanguage": {
      "@type": "Language",
      "alternateName": "en"
    },
    "url": "/projects/statistical-rethinking/chapter_5/chapter5_ex/",
    "datePublished": "0001-01-01T00:00Z",
    "dateModified": "0001-01-01T00:00Z",
    
    
    "description": "",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/projects/statistical-rethinking/chapter_5/chapter5_ex/"
    }
}
    </script>
    


    

    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
    
    




<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#40485A",
          "text": "#ffffff"
        },
        "button": {
          "background": "#5B5A68",
          "text": "#ffffff"
        }
      },
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on my website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://cookies.insites.com"
      }
    })});
</script>


</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/projects">Projects</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/talks">Talks</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/about">About</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/">Home</a>
            </li>
        
        
    </ul>

    
    <a class="subscribe-button icon-feed" href="/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">



<header class="main-header post-head no-cover">
  <nav class="main-nav clearfix">



      <ul>
        
			<li> <a class="blog-logo" href="/">Home</a> </li>
			  
			<li> <a class="blog-logo" href="/about">About</a> </li>
			  
			<li> <a class="blog-logo" href="/talks">Talks</a> </li>
			  
			<li> <a class="blog-logo" href="/projects">Projects</a> </li>
			  

            
              <a class="menu-button icon-feed" href="">&nbsp;&nbsp;Subscribe</a>
            
            
      
       </ul>
    </nav>
    
     <div class="vertical">
        <div class="main-header-content inner">
            


    <a class="bloglogo" href="https://github.com/corriebar" target="_blank">
    <span class="icon-github" style="color:white;font-size:2em"></span>
    </a>
&nbsp;









    <a class="bloglogo" href="https://twitter.com/corrieaar" target="_blank">
        <span class="icon-twitter" style="color:white;font-size:2em"></span>
    </a>
&nbsp;














            <h1 class="page-title">Samples of Thoughts</h1>
            <h2 class="page-description">about data, statistics  and everything in between</h2>
        </div>
    </div>  
    


</header>



<main class="content" role="main">




  <article class="post projects">

    <header class="post-header">
        <h1 class="post-title"></h1>
        <small></small>

        <section class="post-meta">
        
            <p class="post-reading post-line">
            <span>Estimated reading time: 14 min</span>
            </p>
        
        
        
         
        </section>
    </header>

    <section class="post-content">
      

<h1 id="chapter-5-exercises">Chapter 5 - Exercises</h1>

<p>Corrie
June 3, 2018</p>

<h1 id="chapter-5-exercises-1">Chapter 5 - Exercises</h1>

<p>These are my solutions to the exercises from chapter 5.</p>

<h2 id="easy">Easy.</h2>

<p><strong>5E1.</strong> The following linear models are multiple linear regressions:</p>

<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Cbeta_x%20x_i%20%2B%20%5Cbeta_z%20z_i" alt="\\mu\_i = \\beta\_x x\_i + \\beta\_z z\_i" title="\mu_i = \beta_x x_i + \beta_z z_i" /></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Calpha%20%2B%20%5Cbeta_x%20x_i%20%2B%20%5Cbeta_z%20z_i" alt="\\mu\_i = \\alpha + \\beta\_x x\_i + \\beta\_z z\_i" title="\mu_i = \alpha + \beta_x x_i + \beta_z z_i" /></li>
</ul>

<p>whereas the following are bivariate linear regressions:</p>

<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Calpha%20%2B%20%5Cbeta%20x_i" alt="\\mu\_i = \\alpha + \\beta x\_i" title="\mu_i = \alpha + \beta x_i" /></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Calpha%20%2B%20%5Cbeta%28x_i%20-%20z_i%29 &quot;mu_i = alpha + beta(x_i - z_i" alt="\\mu\_i = \\alpha + \\beta(x\_i - z\_i)" />&rdquo;)</li>
</ul>

<p><strong>5E2.</strong> Write down a multiple regression to evaluate the claim: <em>Animal diversity is linearly related to latitude, but only after controlling for plant diversity.</em></p>

<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%2A%7D%0A%5Ctext%7Banimal%20diversity%7D_i%20%26%5Csim%20%5Ctext%7BNormal%7D%28%20%5Cmu_i%2C%20%5Csigma%29%20%5C%5C%0A%5Cmu_i%20%26%3D%20%5Calpha%20%2B%20%5Cbeta_%7Blat%7D%5Ctext%7Blatitude%7D_i%20%2B%20%5Cbeta_%7Bplant%7D%5Ctext%7Bplant%20diversity%7D_i%20%0A%5Cend%7Balign%2A%7D &quot;begin{align*}
text{animal diversity}_i &amp;sim text{Normal}( mu_i, sigma" alt="\\begin{align\*}
\\text{animal diversity}\_i &amp;\\sim \\text{Normal}( \\mu\_i, \\sigma) \\\\
\\mu\_i &amp;= \\alpha + \\beta\_{lat}\\text{latitude}\_i + \\beta\_{plant}\\text{plant diversity}\_i 
\\end{align\*}" /> <br />
\mu<em>i &amp;= \alpha + \beta</em>{lat}\text{latitude}<em>i + \beta</em>{plant}\text{plant diversity}_i
\end{align*}&ldquo;)</p>

<p><strong>5E3.</strong> Write down a multiple regression to evaluate the claim: <em>Neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree.</em></p>

<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%2A%7D%0A%5Ctext%7Btime%20to%20PhD%7D_i%20%26%5Csim%20%5Ctext%7BNormal%7D%28%5Cmu_i%2C%20%5Csigma%29%20%5C%5C%0A%5Cmu_i%20%26%3D%20%5Calpha%20%2B%20%5Cbeta_%7Bf%7D%5Ctext%7Bfunding%7D_i%20%2B%20%5Cbeta_%7Bl%7D%20%5Ctext%7Blab%20size%7D_i%0A%5Cend%7Balign%2A%7D &quot;begin{align*}
text{time to PhD}_i &amp;sim text{Normal}(mu_i, sigma" alt="\\begin{align\*}
\\text{time to PhD}\_i &amp;\\sim \\text{Normal}(\\mu\_i, \\sigma) \\\\
\\mu\_i &amp;= \\alpha + \\beta\_{f}\\text{funding}\_i + \\beta\_{l} \\text{lab size}\_i
\\end{align\*}" /> <br />
\mu<em>i &amp;= \alpha + \beta</em>{f}\text{funding}<em>i + \beta</em>{l} \text{lab size}_i
\end{align*}&ldquo;)</p>

<p>The parameters <img src="https://latex.codecogs.com/png.latex?%5Cbeta_f" alt="\\beta\_f" title="\beta_f" /> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_l" alt="\\beta\_l" title="\beta_l" /> should be both positive (<img src="https://latex.codecogs.com/png.latex?%3E0" alt="&amp;gt;0" title="&gt;0" />).</p>

<p><strong>5E4.</strong> Categorical predictor with 4 levels, labeled A, B, C, and D. <img src="https://latex.codecogs.com/png.latex?A_i" alt="A\_i" title="A_i" />, <img src="https://latex.codecogs.com/png.latex?B_i" alt="B\_i" title="B_i" />, <img src="https://latex.codecogs.com/png.latex?C_i" alt="C\_i" title="C_i" />, and <img src="https://latex.codecogs.com/png.latex?D_i" alt="D\_i" title="D_i" /> are the respective indicator variables. The following are inferentially equivalent ways to include the categorical variables in a regression:</p>

<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Calpha%20%2B%20%5Cbeta_A%20A_i%20%2B%20%5Cbeta_B%20B_i%20%2B%20%5Cbeta_C%20C_i" alt="\\mu\_i = \\alpha + \\beta\_A A\_i + \\beta\_B B\_i + \\beta\_C C\_i" title="\mu_i = \alpha + \beta_A A_i + \beta_B B_i + \beta_C C_i" /></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_i%20%3D%20%5Calpha%20%2B%20%5Cbeta_B%20B_i%20%2B%20%5Cbeta_C%20C_i%20%2B%20%5Cbeta_D%20D_i" alt="\\mu\_i = \\alpha + \\beta\_B B\_i + \\beta\_C C\_i + \\beta\_D D\_i" title="\mu_i = \alpha + \beta_B B_i + \beta_C C_i + \beta_D D_i" /></li>
</ul>

<h2 id="medium">Medium.</h2>

<p><strong>5M1.</strong> Invent your own examples of a spurious correlations. An outcome variable should be correlated with both predictor variables. But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish.</p>

<pre><code class="language-r">n &lt;- 100
x_real &lt;- rnorm(n)
x_spur &lt;- rnorm(n, x_real)
y &lt;- rnorm(n, x_real)

df &lt;- data.frame(x_real=x_real, x_spur=x_spur, y=y)
pairs(df)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-1-1.png" alt="" /></p>

<pre><code class="language-r">library(rethinking)
mod1 &lt;- lm(y ~ ., data=df)
plot( precis(mod1) )
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-2-1.png" alt="" /></p>

<p>Note: I found an article about an interesting spurious correlation: There are various correlations between a name of a person and where they live, what they work, and whom they marry. Apparently, people with similar names tend to marry each other and similarly, choose occupations that sound similar to their own name (e.g. Dennis - dentist). These are spurious correlations: people of the same age tend to marry each other and people of the same age tend to have similar names. The <a href="http://andrewgelman.com/2011/02/09/dennis_the_dent/">article</a> gives a short summary of the confounding variables</p>

<p><strong>5M2.</strong> Invent your own example of a masked relationship. (I have to confess I wasn&rsquo;t very creative here)</p>

<pre><code class="language-r">n &lt;- 100
rho &lt;- 0.7                           # correlation between x_pos and x_neg
x_pos &lt;- rnorm( n )                  # x_pos as Gaussian
x_neg &lt;- rnorm( n, rho*x_pos,        # x_neg correlated with x_pos
                sqrt(1-rho^2) )
y &lt;- rnorm( n, x_pos - x_neg)        # y equally associated with x_pos, x_eg
df &lt;- data.frame(x_pos = x_pos, x_neg=x_neg, y=y)
pairs(df)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-3-1.png" alt="" /></p>

<p>The variables <code>x_pos</code> and <code>x_neg</code> are correlated with each other but based on the plot, it looks as if they don&rsquo;t associate much with the outcome <code>y</code>.</p>

<pre><code class="language-r">mod2 &lt;- lm(y ~ ., data=df)
plot( precis(mod2))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-4-1.png" alt="" /></p>

<p>This unmasks the association and shows that both variables have an association with <code>y</code>.</p>

<p><strong>5M3.</strong> It is sometimes observed that the best predictor of fire risk is the presence of firefighters: States and localities with many firefighters also have more fires. Now, firefighters do not <em>cause</em> fires, but this is not a spurious correlation. Instead, it is fire tat causes firefighters.</p>

<p>In the context of divorce and marriage data: How might a high divorce rate cause a higher marriage rate? A high divorce rate means that there is also a higher number of people that can marry again, thus raising the marriage rate. One way I can think of testing this relationship would be to include the remarriage rate in a multivariate regression.</p>

<p><strong>5M4.</strong> In the divorce data, States with high number of Mormons have much lower divorce rates than the regression model expected. Include percent of Latter-day Saints, LDS, in your regression model. I first downloaded the LDS population by State from <a href="https://en.wikipedia.org/wiki/The_Church_of_Jesus_Christ_of_Latter-day_Saints_membership_statistics_(United_States)">wikipedia</a> (retrieved on June 6, 2018). Next step is to combine the two data frames:</p>

<pre><code class="language-r">library(dplyr)
data(&quot;WaffleDivorce&quot;)
d &lt;- WaffleDivorce
LDS &lt;- read.csv(&quot;LDS.csv&quot;)
d &lt;- d %&gt;% left_join(LDS, by=c(&quot;Location&quot; = &quot;State&quot;)) %&gt;% 
  select(Location, Loc, MedianAgeMarriage, Marriage, Divorce, LDS) %&gt;%
  mutate(Location = as.factor(Location))
head(d)
</code></pre>

<pre><code>##     Location Loc MedianAgeMarriage Marriage Divorce    LDS
## 1    Alabama  AL              25.3     20.2    12.7 0.0077
## 2     Alaska  AK              25.2     26.0    12.5 0.0453
## 3    Arizona  AZ              25.8     20.3    10.8 0.0610
## 4   Arkansas  AR              24.3     26.4    13.5 0.0104
## 5 California  CA              26.8     19.1     8.0 0.0194
## 6   Colorado  CO              25.7     23.5    11.6 0.0270
</code></pre>

<pre><code class="language-r">hist(d$LDS)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-6-1.png" alt="" /></p>

<p>Since the LDS variable is very skewed (most states have almost no LDS population, a few, e.g. Idaho and Utah, have a very high LDS population), it would be better to transform it. We use first a log-transform and then standardize the variable.</p>

<pre><code class="language-r">d$log.LDS &lt;- log(d$LDS)
d$log.LDS.s &lt;- ( d$log.LDS - mean(d$log.LDS) ) / sd(d$log.LDS)
d$LDS.s &lt;- (d$LDS - mean(d$LDS)) / sd(d$LDS)
hist(d$log.LDS.s)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-7-1.png" alt="" /></p>

<p>We also need to standardize the other variables:</p>

<pre><code class="language-r">d$MedianAgeMarriage.s &lt;- (d$MedianAgeMarriage - mean(d$MedianAgeMarriage)) / sd(d$MedianAgeMarriage)
d$Marriage.s &lt;- (d$Marriage - mean(d$Marriage)) / sd(d$Marriage)
</code></pre>

<p>Build the model:</p>

<pre><code class="language-r">mod4 &lt;- map(
  alist(
    Divorce ~ dnorm( mu, sigma),
    mu &lt;- a + bMA*MedianAgeMarriage.s + bMR*Marriage.s + bL*log.LDS.s,
    a ~ dnorm( 0, 10 ),
    c(bMA, bMR, bL) ~ dnorm( 0, 1),
    sigma ~ dunif(0, 10)
  ), data=d
)
precis( mod4 )
</code></pre>

<pre><code>##        Mean StdDev  5.5% 94.5%
## a      9.68   0.19  9.37 10.00
## bMA   -1.29   0.28 -1.74 -0.85
## bMR    0.13   0.30 -0.35  0.61
## bL    -0.54   0.28 -0.98 -0.10
## sigma  1.38   0.14  1.16  1.60
</code></pre>

<pre><code class="language-r">plot(precis( mod4))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-10-1.png" alt="" /></p>

<p>This means, that a higher population is negatively associated with the divorce rate.</p>

<pre><code class="language-r">mu &lt;- link(mod4)
mu.mean &lt;- apply(mu, 2, mean)
mu.PI &lt;- apply(mu, 2, PI)

divorce.sim &lt;- sim( mod4, n=1e4 )
divorce.PI &lt;- apply(divorce.sim, 2, PI)
# residual plot showing the mean prediction error
# compute residuals
divorce.resid &lt;- d$Divorce - mu.mean
# get ordering by divorce rate
o &lt;- order(divorce.resid)
# make the plot
dotchart( divorce.resid[o], labels=d$Loc[o], xlim=c(-6,5), cex=0.6 )
abline(v=0, col=col.alpha(&quot;black&quot;, 0.2))
for (i in 1:nrow(d) ) {
  j &lt;- o[i]    # which State in order
  lines( d$Divorce[j] - c(mu.PI[1, j], mu.PI[2, j]), rep(i,2) )
  points( d$Divorce[j] - c(divorce.PI[1,j], divorce.PI[2, j]), rep(i,2) ,
          pch=3, cex=0.6, col=&quot;gray&quot;)
}
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/fig1-1.png" alt="" /></p>

<p>The model still overestimates the divorce rate for Idaho, but whereas before (without the LDS predictor) it had a mean prediction error of about -4.4, it now has a mean prediction error of about</p>

<pre><code class="language-r">divorce.resid[d$Loc == &quot;ID&quot;]
</code></pre>

<pre><code>## [1] -3.626627
</code></pre>

<p>The mean prediction error for Utah improved similarly.</p>

<p><strong>5M5.</strong> One way to reason through multiple causation hypotheses is to imagine detailed mechanisms through which predictor variables might influence outcomes. Example: It is sometimes argued that the price of gasoline (predictor variable) is positively associated with lower obesity rates (outcome variable). There are two important mechanisms by which the price of as could reduce obesity. (1) high gas prices lead to less driving and thus more walking (2) high gas prices lead to less driving, which leads to less eating out. What multiple regression variables could we use to address these mechanisms? (assuming we can have any predictor variable we want) For the first case, we could include the predictor variable of the average walked distance. To address the second case, a good variable to include would be the average rate of eating out.</p>

<h2 id="hard">Hard.</h2>

<p>All three exercises below use the data <code>foxes</code> about the urban fox <em>Vulpes vulpes</em>. They move in packs and defend territories, so data on habitat quality and population density is included in the data. It also includes the number of social groups an individual fox belongs to, weight of an individual fox, as well as the average amount of food available in a territory, the group size and area of the territory.</p>

<pre><code class="language-r">data(foxes)
d &lt;- foxes
head(d)
</code></pre>

<pre><code>##   group avgfood groupsize area weight
## 1     1    0.37         2 1.09   5.02
## 2     1    0.37         2 1.09   2.84
## 3     2    0.53         2 2.05   5.33
## 4     2    0.53         2 2.05   6.07
## 5     3    0.49         2 2.12   5.85
## 6     3    0.49         2 2.12   3.25
</code></pre>

<pre><code class="language-r">summary(d)
</code></pre>

<pre><code>##      group          avgfood         groupsize          area      
##  Min.   : 1.00   Min.   :0.3700   Min.   :2.000   Min.   :1.090  
##  1st Qu.:11.75   1st Qu.:0.6600   1st Qu.:3.000   1st Qu.:2.590  
##  Median :18.00   Median :0.7350   Median :4.000   Median :3.130  
##  Mean   :17.21   Mean   :0.7517   Mean   :4.345   Mean   :3.169  
##  3rd Qu.:24.00   3rd Qu.:0.8000   3rd Qu.:5.000   3rd Qu.:3.772  
##  Max.   :30.00   Max.   :1.2100   Max.   :8.000   Max.   :5.070  
##      weight     
##  Min.   :1.920  
##  1st Qu.:3.720  
##  Median :4.420  
##  Mean   :4.530  
##  3rd Qu.:5.375  
##  Max.   :7.550
</code></pre>

<p><strong>5H1.</strong> Fit two bivariate Gaussian regressions, using <code>map</code>:</p>

<ol>
<li><code>weight ~ area</code></li>
<li><code>weight ~ groupsize</code></li>
</ol>

<pre><code class="language-r">d$area.s &lt;- (d$area - mean(d$area)) / sd(d$area)
mod5 &lt;- map(
  alist(
    weight ~ dnorm( mu, sigma) ,
    mu &lt;- a + bA*area.s ,
    a ~ dnorm( 0, 100),
    bA ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)
  ), data=d
)
plot( precis( mod5))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-14-1.png" alt="" /></p>

<p>It looks like area is not an important predictor for body weight. Let&rsquo;s have a closer look at some more plots.</p>

<pre><code class="language-r">area.seq &lt;- seq(from=-2.5, to=2.5, length.out = 300)
mu &lt;- link(mod5, data=list(area.s = area.seq))
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI, prob=0.95)
weight.sim &lt;- sim(mod5, data=list(area.s = area.seq))
weight.HPDI &lt;- apply( weight.sim, 2, HPDI, prob=0.95)
plot(  weight ~ area.s, data=d)
lines( area.seq, mu.mean)
shade( mu.HPDI, area.seq)
shade( weight.HPDI, area.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-15-1.png" alt="" /></p>

<p>This plot also suggests that area is not an important predictor. There seems to be no relation at all with area and sigma is relatively large.</p>

<pre><code class="language-r">d$groupsize.s &lt;- (d$groupsize - mean(d$groupsize)) / sd(d$groupsize)
mod6 &lt;- map(
  alist(
    weight ~ dnorm( mu, sigma) ,
    mu &lt;- a + bG*groupsize.s,
    bG ~ dnorm(0, 1),
    a ~ dnorm(0, 10),
    sigma ~ dunif(0, 10)
  ), data=d
)
plot( precis( mod6))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-16-1.png" alt="" /></p>

<p>The group size seems to have some importance, at least it is slightly further away from 0 than the parameter for area.</p>

<pre><code class="language-r">groupsize.seq &lt;- seq(from=-2, to=3, length.out = 300)
mu &lt;- link( mod6, data=list(groupsize.s=groupsize.seq))
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI, prob=0.95)
weight.sim &lt;- sim(mod6, data=list(groupsize.s=groupsize.seq))
weight.HPDI &lt;- apply(weight.sim, 2, HPDI, prob=0.95)
plot( weight ~ groupsize.s, data=d)
lines(groupsize.seq, mu.mean)
shade(mu.HPDI, groupsize.seq)
shade(weight.HPDI, groupsize.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-17-1.png" alt="" /></p>

<p>While there seems to be more of a slope here, it is still very minor and doesn&rsquo;t look like it is an important factor..</p>

<p><strong>5H2.</strong> As before, we try to predict weight, but this time using a multivariate model that uses both the area and group size as predictor.</p>

<pre><code class="language-r">mod7 &lt;- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu &lt;- a + bA*area.s + bG*groupsize.s,
    a ~ dnorm(0, 10),
    bA ~ dnorm(0,1),
    bG ~ dnorm(0,1),
    sigma ~ dunif(0,10)
  ), data=d
)
plot( precis( mod7))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-18-1.png" alt="" /></p>

<p>And surprise surprise, suddenly both area and group size seem to have a discernible importance for predicting body weight. Let&rsquo;s plot the predictions of the model for both predictors, for each holding the other predictor constant at its mean.</p>

<pre><code class="language-r"># Area, holding groupsize fixed
groupsize.avg &lt;- mean(d$groupsize.s)
area.seq &lt;- seq(from=-3, to=3, length.out = 300)
pred.data &lt;- data.frame(groupsize.s=groupsize.avg, area.s=area.seq)
mu &lt;- link(mod7, data=pred.data)
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI, prob=0.95)
weight.sim &lt;- sim(mod7, data=pred.data)
weight.HPDI &lt;- apply(weight.sim, 2, HPDI, prob=0.95)
plot( weight ~ area.s, data=d, type=&quot;n&quot; )
lines(area.seq, mu.mean)
shade(mu.HPDI, area.seq)
shade(weight.HPDI, area.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-19-1.png" alt="" /></p>

<p>Now, we can see a quite clear association between area and weight: A fox living in a bigger territory seems to be heavier than a fox in a smaller territory.</p>

<pre><code class="language-r"># Groupsize, area fixed
area.avg &lt;- mean(d$area.s)
groupsize.seq &lt;- seq(from=-2, to=3, length.out = 300)
pred.data &lt;- data.frame(groupsize.s=groupsize.seq, area.s=area.avg)
mu &lt;- link(mod7, data=pred.data)
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI, prob=0.95)
weight.sim &lt;- sim(mod7, data=pred.data)
weight.HPDI &lt;- apply(weight.sim, 2, HPDI, prob=0.95)
plot( weight ~ groupsize.s, data=d, type=&quot;n&quot;)
lines( groupsize.seq, mu.mean)
shade( mu.HPDI, groupsize.seq)
shade( weight.HPDI, groupsize.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-20-1.png" alt="" /></p>

<p>A larger group is associated with a lower weight (more foxes that need to share food, maybe?).</p>

<p>So why is this? Let&rsquo;s look at the correlation plot of the three variables.</p>

<pre><code class="language-r">pairs( weight ~ groupsize + area, data=d)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-21-1.png" alt="" /></p>

<p>Group size is strongly correlated with area: a larger territory is associated with a larger group of foxes (makes sense, right?). Both area and group size are also correlated with weight: area is positively correlated with weight, while group size is negatively correlated with weight. This circumstance leads to a masked association: the two predictor variables cancel each other out and thus don&rsquo;t seem important.</p>

<p><strong>5H3.</strong> Let&rsquo;s add the average amount of food variable. We fit two more multivariate regressions:</p>

<ol>
<li><code>weight ~ avgfood + groupsize</code></li>
<li><code>weight ~ avgfood + groupsize + area</code></li>
</ol>

<pre><code class="language-r">d$avgfood.s &lt;- (d$avgfood - mean(d$avgfood)) / sd(d$avgfood)
mod8 &lt;- map(
  alist(
    weight ~ dnorm( mu, sigma),
    mu &lt;- a + bF*avgfood.s + bG*groupsize.s,
    a ~ dnorm(0, 10),
    bF ~ dnorm(0,1),
    bG ~ dnorm(0,1),
    sigma ~ dunif(0,10)
  ), data=d
)
plot( precis( mod8))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-22-1.png" alt="" /></p>

<pre><code class="language-r">mod9 &lt;- map(
  alist(
    weight ~ dnorm( mu, sigma),
    mu &lt;- a + bF*avgfood.s + bG*groupsize.s + bA*area.s,
    a ~ dnorm(0, 10),
    c(bF, bG, bA) ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)
  ), data=d
)
plot( precis( mod9))
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-23-1.png" alt="" /></p>

<p>Adding both average amount of food and the area of the territory leads to a decrease in their parameters for both predictor variables, compared with the regressions that contain only of the two. (a) Is <code>avgfood</code> or <code>area</code> a better predictor to include in a model?</p>

<pre><code class="language-r"># Predictor residual plot
mod9.1 &lt;- map(
  alist(
    avgfood.s ~ dnorm( mu, sigma) ,
    mu &lt;- a + b*area.s,
    a ~ dnorm(0, 10),
    b ~ dnorm(0,1),
    sigma ~ dunif(0, 10)
  ), data=d
)

# cpmpute residuals
mu &lt;- coef(mod9.1)['a'] + coef(mod9.1)['b']*d$area.s

# compute residuals
f.resid &lt;- d$avgfood.s - mu

plot( avgfood.s ~ area.s, d, col=rangi2)
abline(mod9.1)
</code></pre>

<pre><code>## Warning in abline(mod9.1): only using the first two of 3 regression
## coefficients
</code></pre>

<pre><code class="language-r">for (i in 1:length(f.resid)) {
  x &lt;- d$area.s[i]
  y &lt;- d$avgfood.s[i]
  # draw the lines segment
  lines( c(x,x), c(mu[i], y), lwd=0.5, col=col.alpha(&quot;black&quot;, 0.5))
}
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-24-1.png" alt="" /></p>

<p>This residual plot shows the residual average amount of food after accounting for the linear association with area. Each line segment is a residual, that is. the distance of observed average amount of food from the expected value, when trying to predict the amount of average food with the area alone. Thus foxes above the regression line have more food than expected and the one below the line have less than expected, according to the area. The residuals are the variation in average amount of food that is left over, after taking out the purely linear relationship between area and average food. We can use these residuals to plot them against the actual outcome of interest, the weight. These are also called predictor residual plots.</p>

<pre><code class="language-r">plot( d$weight ~ f.resid, col=rangi2, xlab=&quot;Average food residuals&quot;, ylab=&quot;Weight&quot;)
abline(a=coef(mod9)['a'], b=coef(mod9)['bF'])
abline(v=0, lty=2)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-25-1.png" alt="" /></p>

<pre><code class="language-r"># Predictor residual plot
mod9.2 &lt;- map(
  alist(
    area.s ~ dnorm( mu, sigma) ,
    mu &lt;- a + b*avgfood.s,
    a ~ dnorm(0, 10),
    b ~ dnorm(0,1),
    sigma ~ dunif(0, 10)
  ), data=d
)

# cpmpute residuals
mu &lt;- coef(mod9.2)['a'] + coef(mod9.2)['b']*d$avgfood.s

# compute residuals
a.resid &lt;- d$area.s - mu

plot( d$weight ~  a.resid, col=rangi2, xlab=&quot;Area residuals&quot;, ylab=&quot;Weight&quot;)
abline(a=coef(mod9)['a'], b=coef(mod9)['bA'])
abline(v=0, lty=2)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-26-1.png" alt="" /></p>

<p>These predictor residual plots can be interpreted as follows: The vertical dashed line indicates an area that exactly matches the expectation from the average amount of food. Thus points to the right of the line represent foxes having more area than expected for their average food and the one to the left have less area than expected for their amount of average food. To both sides, we have about the same weights.</p>

<p>Unfortunately, the plots are about the same for both area and average food, so I don&rsquo;t find them helpful to determine which predictor variable would be better to include in the model.</p>

<p>So let&rsquo;s have a look at the counterfactual plots for both average food and the area.</p>

<pre><code class="language-r"># counterfactual plot of average food, holding area and groupsize fixed
area.avg &lt;- mean(d$area.s)
groupsize.avg &lt;- mean(d$groupsize.s)
avgfood.seq &lt;- seq(from=-2, to=3)
data.pred &lt;- data.frame(area.s=area.avg,
                        groupsize.s=groupsize.avg,
                        avgfood.s=avgfood.seq)
mu &lt;- link(mod9, data=data.pred)
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI)
weight.sim &lt;- sim(mod9, data=data.pred)
weight.HPDI &lt;- apply(weight.sim, 2, HPDI, prob=0.95)
plot( weight ~ avgfood.s, data=d, type=&quot;n&quot;)
lines( avgfood.seq, mu.mean)
shade( mu.HPDI, avgfood.seq)
shade( weight.HPDI, avgfood.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-27-1.png" alt="" /></p>

<p>Now the same for area:</p>

<pre><code class="language-r"># counterfactual plot for area, holding groupsize and average food fixed
avgfood.avg &lt;- mean(d$avgfood.s)
groupsize.avg &lt;- mean(d$groupsize.s)
area.seq &lt;- seq(from=-3, to=3)
data.pred &lt;- data.frame(area.s=area.seq,
                        groupsize.s=groupsize.avg,
                        avgfood.s=avgfood.avg)
mu &lt;- link(mod9, data=data.pred)
mu.mean &lt;- apply(mu, 2, mean)
mu.HPDI &lt;- apply(mu, 2, HPDI)
weight.sim &lt;- sim(mod9, data=data.pred)
weight.HPDI &lt;- apply(weight.sim, 2, HPDI, prob=0.95)
plot( weight ~ area.s, data=d, type=&quot;n&quot;)
lines(area.seq, mu.mean)
shade(mu.HPDI, area.seq)
shade(weight.HPDI, area.seq)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-28-1.png" alt="" /></p>

<p>Both plots look very similar, so they&rsquo;re not very helpful in deciding which of the two variables would be better to include. Based on these plots, I would conclude that in terms of the model, it doesn&rsquo;t make much difference if you include one or the other. I would not recommend to include both though. As we can see in the following plot, both variables are strongly correlated with each other:</p>

<pre><code class="language-r">pairs(weight ~ avgfood + groupsize + area, data=d)
</code></pre>

<p><img src="Chapter5_Ex_files/figure-markdown_github/unnamed-chunk-29-1.png" alt="" /></p>

<pre><code class="language-r">cor( d[,c(&quot;weight&quot;, &quot;avgfood&quot;, &quot;groupsize&quot;, &quot;area&quot;)])
</code></pre>

<pre><code>##                weight     avgfood  groupsize       area
## weight     1.00000000 -0.02503892 -0.1609938 0.01947728
## avgfood   -0.02503892  1.00000000  0.9014829 0.88310378
## groupsize -0.16099376  0.90148290  1.0000000 0.82759448
## area       0.01947728  0.88310378  0.8275945 1.00000000
</code></pre>

<p>The correlations between average food, group size and area are all very high (above 0.8). Especially the correlation of average food with groupsize and area are very high, about 0.9. Which makes sense, since thinking about it, they should all be correlated: More area means more food available, which means a bigger group is sustainable. This high correlation leads to multicollinearity, which also explains why the effect of average food and area is greatly reduced, with higher standard deviation, when both are included in the model. Knowing the area (and group size), adding the average amount of food doesn&rsquo;t add any more useful information. Since I assume that area causes average food which causes weight, I would only include area (the original cause) in my model, but I guess you could also argue that average food is the more direct cause for weight. As said in the chapter, one valid approach is also to just show that using either of the highly correlated predictor variables leads to the same result.</p>

    
    </section>


  <aside class="read-next">
  
      <a class="read-next-story" style="no-cover" href="/projects/statistical-rethinking/chapter_4/chapter4b/">
          <section class="post">
              <h5></h5>
              
          </section>
      </a>
  
  
      <a class="read-next-story prev" style="no-cover" href="/projects/statistical-rethinking/chapter_6/chapter6_ex/">
          <section class="post">
              <h5></h5>
          </section>
      </a>
      

</aside>



  <footer class="post-footer">


    









<section class="author">
  <h4><a href="/">Corrie</a></h4>
  
  <p>Read <a href="/">more posts</a> by this author.</p>
  
  <div class="author-meta">
    
    
  </div>
</section>




    
<section class="share">
  <h4>Share this projects</h4>
  <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=&nbsp;-&nbsp;Samples%20of%20Thoughts&amp;url=%2fprojects%2fstatistical-rethinking%2fchapter_5%2fchapter5_ex%2f"
      onclick="window.open(this.href, 'twitter-share', 'width=550,height=421');return false;">
      <span class="hidden">Twitter</span>
  </a>
  <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=%2fprojects%2fstatistical-rethinking%2fchapter_5%2fchapter5_ex%2f"
      onclick="window.open(this.href, 'facebook-share','width=580,height=551');return false;">
      <span class="hidden">Facebook</span>
  </a>
  <a class="icon-linkedin" style="font-size: 1.4em" href="https://www.linkedin.com/shareArticle?mini=true&title=&url=%2fprojects%2fstatistical-rethinking%2fchapter_5%2fchapter5_ex%2f"
               onclick="window.open(this.href, 'linkedin-share', 'width=554,height=571');return false;">
    <span class="hidden">LinkedIn</span>
    </a>

</section>




    

<div id="disqus_thread"></div>
<script>




var disqus_config = function () {
this.page.url = "\/projects\/statistical-rethinking\/chapter_5\/chapter5_ex\/";  
this.page.identifier = "\/projects\/statistical-rethinking\/chapter_5\/chapter5_ex\/"; 
};

(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://corriebar-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>








  </footer>
</article>

</main>



    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Samples of Thoughts</a> 
        &copy; Corrie Bartelheimer 2020 &middot; </section>
        
    </footer>
    </div>
    <script type="text/javascript" src="/js/jquery.js"></script>
    <script type="text/javascript" src="/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/js/index.js"></script>
    
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>


    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML">
</script>


    
    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
</body>
</html>

