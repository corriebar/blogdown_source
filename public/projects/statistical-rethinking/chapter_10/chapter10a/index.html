<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    
    
        
            <meta name="twitter:card" content="summary"/>
        
    



<meta name="twitter:title" content=""/>
<meta name="twitter:description" content=""/>
<meta name="twitter:site" content="@corrieaar"/>



  	<meta property="og:title" content=" &middot; Samples of Thoughts" />
  	<meta property="og:site_name" content="Samples of Thoughts" />
  	<meta property="og:url" content="/projects/statistical-rethinking/chapter_10/chapter10a/" />

    
        
            <meta property="og:image" content="/images/tea_with_books.jpg"/>
        
    
    
    <meta property="og:description" content="" />
  	<meta property="og:type" content="article" />
    <meta property="article:published_time" content="0001-01-01T00:00:00Z" />

    
    

    <title> &middot; Samples of Thoughts</title>

    
    <meta name="description" content="Binomial Regression Corrie October 4, 2018
Logistic Regression The chimpanzee data: Do chimpanzee pick the more social option?
library(rethinking) data(chimpanz" />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/images/favicon.ico">
	  <link rel="apple-touch-icon" href="/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="/css/nav.css" />

    
    
    


<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/googlecode.min.css' rel='stylesheet' type='text/css' />



  
     
      
          <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Samples of Thoughts" />
      
      
    
    <meta name="generator" content="Hugo 0.55.5" />

    <link rel="canonical" href="/projects/statistical-rethinking/chapter_10/chapter10a/" />

    
      
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name":  null 
    },
    "author": {
        "@type": "Person",
        "name":  null ,
        
        "url":  null ,
        "sameAs": [
            
            
             
             
             
             
             
            
        ]
    },
    "headline": "",
    "name": "",
    "wordCount":  2645 ,
    "timeRequired": "PT13M",
    "inLanguage": {
      "@type": "Language",
      "alternateName": "en"
    },
    "url": "/projects/statistical-rethinking/chapter_10/chapter10a/",
    "datePublished": "0001-01-01T00:00Z",
    "dateModified": "0001-01-01T00:00Z",
    
    
    "description": "",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/projects/statistical-rethinking/chapter_10/chapter10a/"
    }
}
    </script>
    


    

    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
    
    




<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#40485A",
          "text": "#ffffff"
        },
        "button": {
          "background": "#5B5A68",
          "text": "#ffffff"
        }
      },
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on my website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://cookies.insites.com"
      }
    })});
</script>


</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/projects">Projects</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/talks">Talks</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/about">About</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/">Home</a>
            </li>
        
        
    </ul>

    
    <a class="subscribe-button icon-feed" href="/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">



<header class="main-header post-head no-cover">
  <nav class="main-nav clearfix">



      <ul>
        
			<li> <a class="blog-logo" href="/">Home</a> </li>
			  
			<li> <a class="blog-logo" href="/about">About</a> </li>
			  
			<li> <a class="blog-logo" href="/talks">Talks</a> </li>
			  
			<li> <a class="blog-logo" href="/projects">Projects</a> </li>
			  

            
              <a class="menu-button icon-feed" href="">&nbsp;&nbsp;Subscribe</a>
            
            
      
       </ul>
    </nav>
    
     <div class="vertical">
        <div class="main-header-content inner">
            


    <a class="bloglogo" href="https://github.com/corriebar" target="_blank">
    <span class="icon-github" style="color:white;font-size:2em"></span>
    </a>
&nbsp;









    <a class="bloglogo" href="https://twitter.com/corrieaar" target="_blank">
        <span class="icon-twitter" style="color:white;font-size:2em"></span>
    </a>
&nbsp;














            <h1 class="page-title">Samples of Thoughts</h1>
            <h2 class="page-description">about data, statistics  and everything in between</h2>
        </div>
    </div>  
    


</header>



<main class="content" role="main">




  <article class="post projects">

    <header class="post-header">
        <h1 class="post-title"></h1>
        <small></small>

        <section class="post-meta">
        
            <p class="post-reading post-line">
            <span>Estimated reading time: 13 min</span>
            </p>
        
        
        
         
        </section>
    </header>

    <section class="post-content">
      

<h1 id="binomial-regression">Binomial Regression</h1>

<p>Corrie
October 4, 2018</p>

<h2 id="logistic-regression">Logistic Regression</h2>

<p>The chimpanzee data: Do chimpanzee pick the more social option?</p>

<pre><code class="language-r">library(rethinking)
data(chimpanzees)
d &lt;- chimpanzees
</code></pre>

<p>The important variables are the variable <code>condition</code>, indicating if another chimpanzee sits opposite (1) the table or not (0) and the variable <code>prosocial_left</code> which indicates if the left lever is the more social option. These two variables will be used to predict if the chimpanzees pull the left lever or not (<code>pulled_left</code>).</p>

<p>The implied model is:</p>

<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%2A%7D%0AL_i%20%26%5Csim%20%5Ctext%7BBinomial%7D%281%2C%20p_i%29%5C%5C%0A%5Ctext%7Blogit%7D%28p_i%29%20%26%3D%20%5Calpha%20%2B%20%28%5Cbeta_P%20%2B%20%5Cbeta_%7BPC%7DC_i%29P_i%20%5C%5C%0A%5Calpha%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%5C%5C%0A%5Cbeta_P%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%5C%5C%0A%5Cbeta_%7BPC%7D%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%0A%5Cend%7Balign%2A%7D &quot;begin{align*}
L_i &amp;sim text{Binomial}(1, p_i" alt="\\begin{align\*}
L\_i &amp;\\sim \\text{Binomial}(1, p\_i)\\\\
\\text{logit}(p\_i) &amp;= \\alpha + (\\beta\_P + \\beta\_{PC}C\_i)P\_i \\\\
\\alpha &amp;\\sim \\text{Normal}(0, 10) \\\\
\\beta\_P &amp;\\sim \\text{Normal}(0, 10) \\\\
\\beta\_{PC} &amp;\\sim \\text{Normal}(0, 10) 
\\end{align\*}" /><br />
\text{logit}(p_i) &amp;= \alpha + (\beta<em>P + \beta</em>{PC}C_i)P_i <br />
\alpha &amp;\sim \text{Normal}(0, 10) <br />
\beta<em>P &amp;\sim \text{Normal}(0, 10) <br />
\beta</em>{PC} &amp;\sim \text{Normal}(0, 10)
\end{align*}&ldquo;)</p>

<p>We&rsquo;ll write this as a <code>map()</code> model but will start with two simpler models with less predictors, starting with one model that has only an intercept and no predictor variables:</p>

<pre><code class="language-r">m10.1 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a,
    a ~ dnorm(0, 10)
  ),
  data=d
)
precis(m10.1)
</code></pre>

<pre><code>  Mean StdDev 5.5% 94.5%
a 0.32   0.09 0.18  0.46
</code></pre>

<p>This implies a MAP probability of pulling the left lever of</p>

<pre><code class="language-r">logistic(0.32)
</code></pre>

<pre><code>[1] 0.5793243
</code></pre>

<p>with a 89% interval of</p>

<pre><code class="language-r">logistic( c(0.18, 0.46))
</code></pre>

<pre><code>[1] 0.5448789 0.6130142
</code></pre>

<p>Next the models using the predictors:</p>

<pre><code class="language-r">m10.2 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a + bp*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10)
  ),
  data=d
)
m10.3 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a + (bp + bpC*condition)*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data=d
)

(cp &lt;- compare(m10.1, m10.2, m10.3) )
</code></pre>

<pre><code>       WAIC pWAIC dWAIC weight   SE  dSE
m10.2 680.5     2   0.0   0.69 9.20   NA
m10.3 682.2     3   1.7   0.29 9.43 0.73
m10.1 688.0     1   7.5   0.02 7.17 6.10
</code></pre>

<p>The model without the interaction seems to fare better even though the third model best reflects the structure of the experiment.</p>

<pre><code class="language-r">plot( cp , 
      xlim=c( min( cp@output$WAIC - cp@output$SE) , 
              max(cp@output$WAIC + cp@output$SE ) ) )
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-6-1.png" alt="" /></p>

<p>Note also that the difference has a small standard error, so the order of the models wouldn&rsquo;t easily change.</p>

<p>Let&rsquo;s have a look at the third model to understand why it performs poorly compared with the second one:</p>

<pre><code class="language-r">precis(m10.3)
</code></pre>

<pre><code>     Mean StdDev  5.5% 94.5%
a    0.05   0.13 -0.15  0.25
bp   0.61   0.23  0.25  0.97
bpC -0.10   0.26 -0.53  0.32
</code></pre>

<pre><code class="language-r">plot( precis(m10.3) )
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-8-1.png" alt="" /></p>

<p>The interaction variable has a rather wide posterior. Let&rsquo;s have a closer look at the parameter <code>bp</code> for the effect of the prosocial option. We have to distinguish between the absolute and relative effect.</p>

<p>Changing the predictor <code>prosoc_left</code> from 0 to 1 increases the log-odds of pulling the left-hand lever by 0.61. This implies the odds are multiplied by:</p>

<pre><code class="language-r">exp(0.61)
</code></pre>

<pre><code>[1] 1.840431
</code></pre>

<p>That is, the odds increase by 84%. This is the relative effect. The relative effect depend strongly on the other parameter als well. If we assume for example an <img src="https://latex.codecogs.com/png.latex?%5Calpha" alt="\\alpha" title="\alpha" /> value of 4 then the probability for a pull, ignoring everything else:</p>

<pre><code class="language-r">logistic(4)
</code></pre>

<pre><code>[1] 0.9820138
</code></pre>

<p>is already quite high. Adding then the increase of 0.61 (relative increase of 84%) changes this to</p>

<pre><code class="language-r">logistic(4 + 0.61)
</code></pre>

<pre><code>[1] 0.9901462
</code></pre>

<p>In this example, the absolute effect would thus be small.</p>

<p>Let&rsquo;s plot the absolute effect:</p>

<pre><code class="language-r"># dummy data for predictions across treatments
d.pred &lt;- data.frame(
  prosoc_left = c(0, 1, 0, 1), # right/left/right/left
  condition = c(0, 0, 1, 1)    # control/control/partner/partner
)

# build prediction ensemble
chimp.ensemble &lt;- ensemble(m10.1, m10.2, m10.3, data=d.pred)

# summarize
pred.p &lt;- apply(chimp.ensemble$link, 2, mean)
pred.p.PI &lt;- apply(chimp.ensemble$link, 2, PI)
</code></pre>

<pre><code class="language-r">plot( 0, 0, type=&quot;n&quot;, xlab=&quot;prosoc_left/condition&quot;,
      ylab=&quot;proportion pulled left&quot;,
      ylim=c(0,1), xaxt=&quot;n&quot;, xlim=c(1,4) )
axis(1, at=1:4, labels=c(&quot;0/0&quot;, &quot;1/0&quot;, &quot;0/1&quot;, &quot;1/1&quot;))

p &lt;- by( d$pulled_left,
    list(d$prosoc_left, d$condition, d$actor ), mean)

for ( chimp in 1:7) 
  lines( 1:4, as.vector(p[,,chimp]),
         col=&quot;royalblue4&quot;, lwd=1.5)

lines( 1:4, pred.p )
shade(pred.p.PI, 1:4)
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-13-1.png" alt="" /></p>

<p>Compare the MAP model with a MCMC Stan model:</p>

<pre><code class="language-r"># clean NAs from the data
d2 &lt;- d
d2$recipient &lt;- NULL

# re-use map fit to get the formula
m10.3stan &lt;- map2stan(m10.3, data=d2, iter=1e4, warmup=1000 )
precis(m10.3stan)
</code></pre>

<pre><code class="language-r">precis(m10.3stan)
</code></pre>

<pre><code>     Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a    0.05   0.13      -0.15       0.25  5127    1
bp   0.62   0.23       0.25       0.98  4138    1
bpC -0.10   0.26      -0.52       0.32  4797    1
</code></pre>

<p>The numbers are almost identical with the MAP model and we can check the pairs plot to see that the posterior is indeed well approximated by a quadratic.</p>

<pre><code class="language-r">pairs(m10.3stan)
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-16-1.png" alt="" /></p>

<p>We saw in the plot of the average proportions pulled left above that some chimpanzees have a preference for pulling the left or right lever. One even always pulled the left lever. A factor here might be the handedness of the chimp. One thing we can do, is to fit an intercept for each individula:</p>

<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%2A%7D%0AL_i%20%26%5Csim%20%5Ctext%7BBinomial%7D%281%2C%20p_i%29%5C%5C%0A%5Ctext%7Blogit%7D%28p_i%29%20%26%3D%20%5Calpha_%7B%5Ctext%7BACTOR%7D%5Bi%5D%7D%20%2B%20%28%5Cbeta_P%20%2B%20%5Cbeta_%7BPC%7DC_i%29P_i%20%5C%5C%0A%5Calpha%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%5C%5C%0A%5Cbeta_P%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%5C%5C%0A%5Cbeta_%7BPC%7D%20%26%5Csim%20%5Ctext%7BNormal%7D%280%2C%2010%29%20%0A%5Cend%7Balign%2A%7D &quot;begin{align*}
L_i &amp;sim text{Binomial}(1, p_i" alt="\\begin{align\*}
L\_i &amp;\\sim \\text{Binomial}(1, p\_i)\\\\
\\text{logit}(p\_i) &amp;= \\alpha\_{\\text{ACTOR}\[i\]} + (\\beta\_P + \\beta\_{PC}C\_i)P\_i \\\\
\\alpha &amp;\\sim \\text{Normal}(0, 10) \\\\
\\beta\_P &amp;\\sim \\text{Normal}(0, 10) \\\\
\\beta\_{PC} &amp;\\sim \\text{Normal}(0, 10) 
\\end{align\*}" /><br />
\text{logit}(p<em>i) &amp;= \alpha</em>{\text{ACTOR}[i]} + (\beta<em>P + \beta</em>{PC}C_i)P_i <br />
\alpha &amp;\sim \text{Normal}(0, 10) <br />
\beta<em>P &amp;\sim \text{Normal}(0, 10) <br />
\beta</em>{PC} &amp;\sim \text{Normal}(0, 10)
\end{align*}&ldquo;)</p>

<p>We fit this with MCMC since it will turn out to have some skew in its posterior distribution.</p>

<pre><code class="language-r">m10.4 &lt;- map2stan(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a[actor] + (bp + bpC*condition)*prosoc_left,
    a[actor] ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data=d2, chains=2, iter=2500, warmup=500
)
</code></pre>

<p>Number of actors:</p>

<pre><code class="language-r">unique(d$actor)
</code></pre>

<pre><code>[1] 1 2 3 4 5 6 7
</code></pre>

<pre><code class="language-r">precis(m10.4, depth=2)
</code></pre>

<pre><code>      Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a[1] -0.73   0.27      -1.17      -0.31  3365    1
a[2] 10.79   5.17       3.35      18.02  1566    1
a[3] -1.06   0.28      -1.48      -0.59  3205    1
a[4] -1.05   0.28      -1.47      -0.57  2697    1
a[5] -0.74   0.27      -1.17      -0.30  3095    1
a[6]  0.23   0.27      -0.24       0.63  3253    1
a[7]  1.81   0.39       1.21       2.45  3528    1
bp    0.84   0.27       0.40       1.27  2005    1
bpC  -0.14   0.31      -0.61       0.38  2902    1
</code></pre>

<p>This posterior is not entirely Gaussian:</p>

<pre><code class="language-r">post &lt;- extract.samples( m10.4)
str(post)
</code></pre>

<pre><code>List of 3
 $ a  : num [1:4000, 1:7] -0.434 -1.233 -0.671 -1.206 -0.585 ...
 $ bp : num [1:4000(1d)] 0.523 0.906 1.16 1.205 0.594 ...
 $ bpC: num [1:4000(1d)] -0.356 -0.2 -0.413 -0.285 0.193 ...
</code></pre>

<pre><code class="language-r">dens(post$a[,2])
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-21-1.png" alt="" /></p>

<p>Plotting the predictions for each actor:</p>

<pre><code class="language-r">par(mfrow=c(4, 2))
for (chimp in 1:7) {
  d.pred &lt;- list(
    pulled_left = rep(0, 4),       # empty outcomes
    prosoc_left = c(0, 1, 0, 1),   # right/left/right/left
    condition = c(0, 0, 1, 1),     # control/control/partner/partner
    actor = rep(chimp, 4)
  )
  link.m10.4 &lt;- link( m10.4, data=d.pred)
  pred.p &lt;- apply( link.m10.4, 2, mean)
  pred.p.PI &lt;- apply( link.m10.4, 2, PI )
  
  plot(0, 0, type=&quot;n&quot;, xlab=&quot;prosoc_left/condition&quot;,
       ylab=&quot;proportion pulled left&quot;,
       ylim=c(0,1), xaxt=&quot;n&quot;,
       xlim=c(1, 4), yaxp=c(0,1,2) )
  axis(1, at=1:4, labels=c(&quot;0/0&quot;, &quot;1/0&quot;, &quot;0/1&quot;, &quot;1/1&quot;))
  mtext(paste( &quot;actor&quot;, chimp ))
  
  p &lt;- by( d$pulled_left,
           list(d$prosoc_left, d$condition, d$actor), mean )
  lines( 1:4, as.vector(p[,,chimp]), col=&quot;royalblue4&quot;, lwd=2)
  
  lines(1:4, pred.p)
  shade(pred.p.PI, 1:4)
}
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-22-1.png" alt="" /></p>

<h2 id="aggregated-binomial">Aggregated binomial</h2>

<h3 id="chimpanzees">Chimpanzees</h3>

<p>Instead of predicting the likelihood for a single pull (0 or 1), we can also predict the counts, i.e. how likely is it that an actor pulls left <code>x</code> times out of 18 trials.</p>

<pre><code class="language-r">data(chimpanzees)
d &lt;- chimpanzees
d.aggregated &lt;- aggregate( d$pulled_left,
                           list(prosoc_left=d$prosoc_left,
                                condition=d$condition,
                                actor=d$actor),
                           sum)
knitr::kable( head(d.aggregated,  8) )
</code></pre>

<table>
<thead>
<tr>
<th align="right">prosoc_left</th>
<th align="right">condition</th>
<th align="right">actor</th>
<th align="right">x</th>
</tr>
</thead>

<tbody>
<tr>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">9</td>
</tr>

<tr>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">5</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">10</td>
</tr>

<tr>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>

<tr>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>
</tbody>
</table>

<pre><code class="language-r">m10.5 &lt;- map(
  alist(
    x ~ dbinom( 18, p ),
    logit(p) &lt;- a + (bp + bpC*condition)*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data = d.aggregated
)
precis(m10.5)
</code></pre>

<pre><code>     Mean StdDev  5.5% 94.5%
a    0.05   0.13 -0.15  0.25
bp   0.61   0.23  0.25  0.97
bpC -0.10   0.26 -0.53  0.32
</code></pre>

<p>Compare with the same model with non-aggregated data:</p>

<pre><code class="language-r">precis(m10.3stan)
</code></pre>

<pre><code>     Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a    0.05   0.13      -0.15       0.25  5127    1
bp   0.62   0.23       0.25       0.98  4138    1
bpC -0.10   0.26      -0.52       0.32  4797    1
</code></pre>

<p>We get the same estimates.</p>

<h3 id="graduate-school-admissions">Graduate school admissions</h3>

<pre><code class="language-r">data(&quot;UCBadmit&quot;)
d &lt;- UCBadmit
knitr::kable(d)
</code></pre>

<table>
<thead>
<tr>
<th align="left">dept</th>
<th align="left">applicant.gender</th>
<th align="right">admit</th>
<th align="right">reject</th>
<th align="right">applications</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">A</td>
<td align="left">male</td>
<td align="right">512</td>
<td align="right">313</td>
<td align="right">825</td>
</tr>

<tr>
<td align="left">A</td>
<td align="left">female</td>
<td align="right">89</td>
<td align="right">19</td>
<td align="right">108</td>
</tr>

<tr>
<td align="left">B</td>
<td align="left">male</td>
<td align="right">353</td>
<td align="right">207</td>
<td align="right">560</td>
</tr>

<tr>
<td align="left">B</td>
<td align="left">female</td>
<td align="right">17</td>
<td align="right">8</td>
<td align="right">25</td>
</tr>

<tr>
<td align="left">C</td>
<td align="left">male</td>
<td align="right">120</td>
<td align="right">205</td>
<td align="right">325</td>
</tr>

<tr>
<td align="left">C</td>
<td align="left">female</td>
<td align="right">202</td>
<td align="right">391</td>
<td align="right">593</td>
</tr>

<tr>
<td align="left">D</td>
<td align="left">male</td>
<td align="right">138</td>
<td align="right">279</td>
<td align="right">417</td>
</tr>

<tr>
<td align="left">D</td>
<td align="left">female</td>
<td align="right">131</td>
<td align="right">244</td>
<td align="right">375</td>
</tr>

<tr>
<td align="left">E</td>
<td align="left">male</td>
<td align="right">53</td>
<td align="right">138</td>
<td align="right">191</td>
</tr>

<tr>
<td align="left">E</td>
<td align="left">female</td>
<td align="right">94</td>
<td align="right">299</td>
<td align="right">393</td>
</tr>

<tr>
<td align="left">F</td>
<td align="left">male</td>
<td align="right">22</td>
<td align="right">351</td>
<td align="right">373</td>
</tr>

<tr>
<td align="left">F</td>
<td align="left">female</td>
<td align="right">24</td>
<td align="right">317</td>
<td align="right">341</td>
</tr>
</tbody>
</table>

<p>The data set contains only 12 rows but since it is aggregated, it actually represents 4526 applications. The goal is to evaluate whether the data contains evidence for gender bias in admission.</p>

<p>We will fit two models: One using gender as a predictor for <code>admit</code> and one modelling <code>admit</code> as a constant, ignoring gender.</p>

<pre><code class="language-r">d$male &lt;- ifelse( d$applicant.gender == &quot;male&quot;, 1, 0 )

m10.6 &lt;- map(
  alist(
    admit ~ dbinom( applications, p ),
    logit(p) &lt;- a + bm*male,
    a ~ dnorm(0, 10),
    bm ~ dnorm(0, 10)
  ),
  data=d
)

m10.7 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a,
    a ~ dnorm(0, 10)
  ),
  data=d
)
</code></pre>

<pre><code class="language-r">(cp &lt;- compare( m10.6, m10.7 ) )
</code></pre>

<pre><code>        WAIC pWAIC dWAIC weight    SE   dSE
m10.6 5955.0   2.1   0.0      1 34.88    NA
m10.7 6046.2   0.9  91.2      0 29.94 19.15
</code></pre>

<p>The model using male as a predictor performs better than without. The comparison suggests that gender actually matters a lot:</p>

<pre><code class="language-r">plot( cp , 
      xlim=c( min( cp@output$WAIC - cp@output$SE) , 
              max(cp@output$WAIC + cp@output$SE ) ) )
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-29-1.png" alt="" /></p>

<p>In which way does it matter?</p>

<pre><code class="language-r">precis( m10.6 )
</code></pre>

<pre><code>    Mean StdDev  5.5% 94.5%
a  -0.83   0.05 -0.91 -0.75
bm  0.61   0.06  0.51  0.71
</code></pre>

<p>Being male does improve the chances of being admitted. The relative difference is <code>exp(0.61) =</code> 1.8404314. This means that a male applicant&rsquo;s odds are 184% of a female applicant. Let&rsquo;s get the absolute scale, which is more important:</p>

<pre><code class="language-r">post &lt;- extract.samples( m10.6 )
p.admit.male &lt;- logistic( post$a + post$bm )
p.admit.female &lt;- logistic( post$a )

diff.admit &lt;- p.admit.male - p.admit.female

quantile( diff.admit, c(0.025, 0.5, 0.975 ))
</code></pre>

<pre><code>     2.5%       50%     97.5% 
0.1130350 0.1418460 0.1698431 
</code></pre>

<p>Thus the median estimate of the male advantage is about 14%.</p>

<pre><code class="language-r">dens( diff.admit )
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-32-1.png" alt="" /></p>

<pre><code class="language-r">postcheck( m10.6, n=1e4 , col=&quot;royalblue4&quot;)

# draw lines connecting points from same dept
for ( i in 1:6 ){
  x &lt;- 1 + 2*(i-1)
  y1 &lt;- d$admit[x]/d$applications[x]       # male
  y2 &lt;- d$admit[x+1]/d$applications[x+1]   # female
  lines( c(x, x+1), c(y1, y2), col=&quot;royalblue4&quot;, lwd=2)
  text(x+0.5, (y1 + y2)/2 + 0.05, d$dept[x], cex=0.8, col=&quot;royalblue4&quot;)
}
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-33-1.png" alt="" /></p>

<p>The first point of a line is the admission rate for males while the second point of a line is the admission rate for females. The expeted predictions are the black open points and the black crosses indicate the 89% interval of the expectations. The plot shows that only two departments (C and E) and lower admission rates for females. How come we get such a bad prediction?</p>

<p>The problem: Male and female applicants don&rsquo;t apply to the same departments and departments have different admission rates. Department A has much higer admission rates than department F and female applicants apply more often to F than to A.</p>

<p>We will build a model that uses a unique intercept per department.</p>

<pre><code class="language-r"># make index
d$dept_id &lt;- coerce_index( d$dept )

# model with unique intercept for each dept
m10.8 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a[dept_id],
    a[dept_id] ~ dnorm(0, 10)
  ),
  data=d
)

m10.9 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a[dept_id] + bm*male,
    a[dept_id] ~ dnorm(0, 10),
    bm ~ dnorm(0, 10)
  ),
  data=d
)
</code></pre>

<p>We then compare all three models:</p>

<pre><code class="language-r">(cp &lt;- compare( m10.6, m10.7, m10.8, m10.9 ) )
</code></pre>

<pre><code>        WAIC pWAIC dWAIC weight    SE   dSE
m10.8 5201.0   6.0   0.0   0.59 56.99    NA
m10.9 5201.8   7.1   0.8   0.41 57.22  2.47
m10.6 5954.9   2.0 753.9   0.00 35.03 48.46
m10.7 6046.2   0.9 845.2   0.00 29.93 52.31
</code></pre>

<p>As a plot:</p>

<pre><code class="language-r">plot( cp , 
      xlim=c( min( cp@output$WAIC - cp@output$SE) , 
              max(cp@output$WAIC + cp@output$SE ) ) )
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-36-1.png" alt="" /></p>

<p>The two new models with the unique intercepts perform much better. Now, the model without <code>male</code> is ranked first but the difference between the first two models is tiny. Both models got about half the Akaike weight so you could call it a tie.</p>

<p>So how does gender now affect admission?</p>

<pre><code class="language-r">precis( m10.9, depth=2 )
</code></pre>

<pre><code>      Mean StdDev  5.5% 94.5%
a[1]  0.68   0.10  0.52  0.84
a[2]  0.64   0.12  0.45  0.82
a[3] -0.58   0.07 -0.70 -0.46
a[4] -0.61   0.09 -0.75 -0.48
a[5] -1.06   0.10 -1.22 -0.90
a[6] -2.62   0.16 -2.88 -2.37
bm   -0.10   0.08 -0.23  0.03
</code></pre>

<p>The estimate for <code>bm</code> has changed direction, meaning it now estimates that being male is a disadvantage! The estimate becomes <code>exp(-0.1) =</code> 0.9048374. So a male has about 90% the odds of admission as a female.</p>

<p>Let&rsquo;s do the posterior check again as before:</p>

<pre><code class="language-r">postcheck( m10.9, n=1e4 , col=&quot;royalblue4&quot;)

# draw lines connecting points from same dept
for ( i in 1:6 ){
  x &lt;- 1 + 2*(i-1)
  y1 &lt;- d$admit[x]/d$applications[x]       # male
  y2 &lt;- d$admit[x+1]/d$applications[x+1]   # female
  lines( c(x, x+1), c(y1, y2), col=&quot;royalblue4&quot;, lwd=2)
  text(x+0.5, (y1 + y2)/2 + 0.05, d$dept[x], cex=0.8, col=&quot;royalblue4&quot;)
}
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-38-1.png" alt="" /></p>

<p>The predictions fit much better than before.</p>

<p>Let&rsquo;s also check the quadratic approximation. In the example with the chimpanzees, unique intercepts were a problem for quadratic approximations, so let&rsquo;s check how the compare to a Stan model:</p>

<pre><code class="language-r">dstan &lt;- d[, c(&quot;admit&quot;, &quot;applications&quot;, &quot;male&quot;, &quot;dept_id&quot;)]
m10.9stan &lt;- map2stan( m10.9, data=dstan,
                       chains=2, iter=2500, warmup=500)
precis(m10.9stan, depth=2)
</code></pre>

<pre><code class="language-r">pairs(m10.9stan)
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-40-1.png" alt="" /></p>

<p>All the posterior distributions are pretty much Gaussian, a quadratic approximation thus gives good estimates.</p>

<h2 id="fitting-binomial-regression-with-glm">Fitting binomial regression with <code>glm</code></h2>

<p>The following code yields similar results as the map approach for the aggregated binomial.</p>

<pre><code class="language-r">m10.7glm &lt;- glm( cbind( admit, reject) ~ 1, data=d, family=binomial)
m10.6glm &lt;- glm( cbind( admit, reject) ~ male, data=d, family=binomial)
m10.8glm &lt;- glm( cbind( admit, reject) ~ dept, data=d, family=binomial)
m10.9glm &lt;- glm( cbind( admit, reject) ~ male + dept, data=d, 
                 family=binomial )
precis(m10.9glm)
</code></pre>

<pre><code>             Mean StdDev  5.5% 94.5%
(Intercept)  0.68   0.10  0.52  0.84
male        -0.10   0.08 -0.23  0.03
deptB       -0.04   0.11 -0.22  0.13
deptC       -1.26   0.11 -1.43 -1.09
deptD       -1.29   0.11 -1.46 -1.13
deptE       -1.74   0.13 -1.94 -1.54
deptF       -3.31   0.17 -3.58 -3.03
</code></pre>

<p>Compare with the <code>map()</code> model:</p>

<pre><code class="language-r">precis(m10.9stan, depth=2)
</code></pre>

<pre><code>      Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a[1]  0.68   0.10       0.52       0.83  1950    1
a[2]  0.64   0.12       0.45       0.82  2281    1
a[3] -0.58   0.07      -0.70      -0.46  4000    1
a[4] -0.61   0.09      -0.75      -0.47  2889    1
a[5] -1.06   0.10      -1.21      -0.89  4000    1
a[6] -2.64   0.16      -2.89      -2.39  4000    1
bm   -0.10   0.08      -0.22       0.03  1635    1
</code></pre>

<p>Note that the departments are coded differently: the intercept in the <code>glm</code> model corresponds to <code>a[1]</code> in the Stan model and <code>deptB</code> in the <code>glm</code> model corresponds to the difference from department A to B, that is <code>a[2]-a[1]</code> in the Stan model.</p>

<p>To use <code>glm()</code> for a non-aggregated model:</p>

<pre><code class="language-r">m10.4glm &lt;- glm(
  pulled_left ~ as.factor(actor) + prosoc_left*condition  -condition,
  data=chimpanzees, family=binomial
)
precis(m10.4glm)
</code></pre>

<pre><code>                       Mean StdDev     5.5%   94.5%
(Intercept)           -0.73   0.27    -1.16   -0.30
as.factor(actor)2     18.95 754.98 -1187.65 1225.55
as.factor(actor)3     -0.30   0.35    -0.86    0.25
as.factor(actor)4     -0.30   0.35    -0.86    0.25
as.factor(actor)5      0.00   0.34    -0.55    0.55
as.factor(actor)6      0.94   0.35     0.38    1.50
as.factor(actor)7      2.48   0.45     1.76    3.20
prosoc_left            0.82   0.26     0.40    1.24
prosoc_left:condition -0.13   0.30    -0.61    0.34
</code></pre>

<p>We need to use <code>-condition</code> to remove the main effect of condition.</p>

<p>We can also use <code>glimmer()</code> to get code corresponding to a <code>map</code> or <code>map2stan</code> model.</p>

<pre><code class="language-r">glimmer( pulled_left ~ prosoc_left*condition -condition,
         data=chimpanzees, family=binomial)
</code></pre>

<pre><code>alist(
    pulled_left ~ dbinom( 1 , p ),
    logit(p) &lt;- Intercept +
        b_prosoc_left*prosoc_left +
        b_prosoc_left_X_condition*prosoc_left_X_condition,
    Intercept ~ dnorm(0,10),
    b_prosoc_left ~ dnorm(0,10),
    b_prosoc_left_X_condition ~ dnorm(0,10)
)
</code></pre>

<p>Note that <code>glm</code> uses flat priors by default which can lead to nonsense estimates. Consider for example the following example:</p>

<pre><code class="language-r"># almost perfectly associated
y &lt;- c( rep(0, 10), rep(1, 10))
x &lt;- c(rep(-1, 9), rep(1, 11))
m.bad &lt;- glm( y ~ x, data=list(x=x, y=y), family=binomial)
precis(m.bad)
</code></pre>

<pre><code>             Mean  StdDev     5.5%   94.5%
(Intercept) -9.13 2955.06 -4731.89 4713.63
x           11.43 2955.06 -4711.33 4734.19
</code></pre>

<p>The estimates would suggest there is no association between <code>x</code> and <code>y</code> even though there is a strong association. A weak prior helps:</p>

<pre><code class="language-r">m.good &lt;- map(
  alist(
    y ~ dbinom(1, p),
    logit(p) &lt;- a + b*x,
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 10)
  ),
  data=list(x=x, y=y)
)
precis(m.good)
</code></pre>

<pre><code>   Mean StdDev  5.5% 94.5%
a -1.73   2.78 -6.16  2.71
b  4.02   2.78 -0.42  8.45
</code></pre>

<p>Since the uncertainty is not symmetric in this case, the quadratic assumption is misleading. Even better would be MCMC samples:</p>

<pre><code class="language-r">m.better &lt;- map2stan( m.good)
pairs(m.better)
</code></pre>

<p><img src="chapter10a_files/figure-markdown_github/unnamed-chunk-47-1.png" alt="" /></p>

    
    </section>


  <aside class="read-next">
  
      <a class="read-next-story" style="no-cover" href="/projects/statistical-rethinking/chapter_10/chapter10_ex/">
          <section class="post">
              <h5></h5>
              
          </section>
      </a>
  
  
      <a class="read-next-story prev" style="no-cover" href="/projects/statistical-rethinking/chapter_10/chapter10b/">
          <section class="post">
              <h5></h5>
          </section>
      </a>
      

</aside>



  <footer class="post-footer">


    









<section class="author">
  <h4><a href="/">Corrie</a></h4>
  
  <p>Read <a href="/">more posts</a> by this author.</p>
  
  <div class="author-meta">
    
    
  </div>
</section>




    
<section class="share">
  <h4>Share this projects</h4>
  <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=&nbsp;-&nbsp;Samples%20of%20Thoughts&amp;url=%2fprojects%2fstatistical-rethinking%2fchapter_10%2fchapter10a%2f"
      onclick="window.open(this.href, 'twitter-share', 'width=550,height=421');return false;">
      <span class="hidden">Twitter</span>
  </a>
  <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=%2fprojects%2fstatistical-rethinking%2fchapter_10%2fchapter10a%2f"
      onclick="window.open(this.href, 'facebook-share','width=580,height=551');return false;">
      <span class="hidden">Facebook</span>
  </a>
  <a class="icon-linkedin" style="font-size: 1.4em" href="https://www.linkedin.com/shareArticle?mini=true&title=&url=%2fprojects%2fstatistical-rethinking%2fchapter_10%2fchapter10a%2f"
               onclick="window.open(this.href, 'linkedin-share', 'width=554,height=571');return false;">
    <span class="hidden">LinkedIn</span>
    </a>

</section>




    

<div id="disqus_thread"></div>
<script>




var disqus_config = function () {
this.page.url = "\/projects\/statistical-rethinking\/chapter_10\/chapter10a\/";  
this.page.identifier = "\/projects\/statistical-rethinking\/chapter_10\/chapter10a\/"; 
};

(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://corriebar-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>








  </footer>
</article>

</main>



    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Samples of Thoughts</a> 
        &copy; Corrie Bartelheimer 2020 &middot; </section>
        
    </footer>
    </div>
    <script type="text/javascript" src="/js/jquery.js"></script>
    <script type="text/javascript" src="/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/js/index.js"></script>
    
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>


    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML">
</script>


    
    
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-140745376-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


    
</body>
</html>

